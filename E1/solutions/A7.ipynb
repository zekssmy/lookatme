{"cells":[{"cell_type":"code","execution_count":12,"id":"7afe9f49","metadata":{"id":"7afe9f49","executionInfo":{"status":"ok","timestamp":1652132137708,"user_tz":-120,"elapsed":220,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}}},"outputs":[],"source":["import pandas as pd\n","import sklearn\n","import numpy as np"]},{"cell_type":"markdown","id":"4e914cea","metadata":{"id":"4e914cea"},"source":["a) Load Breast Cancer Wisconsin Data Set"]},{"cell_type":"code","execution_count":13,"id":"0c51e501","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"0c51e501","executionInfo":{"status":"ok","timestamp":1652132139476,"user_tz":-120,"elapsed":639,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}},"outputId":"a35020e2-0408-451a-e8fc-f236e7e8140a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    1      2      3       4       5        6        7        8        9   \\\n","0    M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n","1    M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017   \n","2    M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790   \n","3    M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n","4    M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n","..  ..    ...    ...     ...     ...      ...      ...      ...      ...   \n","564  M  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890   \n","565  M  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791   \n","566  M  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302   \n","567  M  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200   \n","568  B   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000   \n","\n","         10  ...      22     23      24      25       26       27      28  \\\n","0    0.2419  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n","1    0.1812  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n","2    0.2069  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n","3    0.2597  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n","4    0.1809  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n","..      ...  ...     ...    ...     ...     ...      ...      ...     ...   \n","564  0.1726  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n","565  0.1752  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n","566  0.1590  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n","567  0.2397  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n","568  0.1587  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n","\n","         29      30       31  \n","0    0.2654  0.4601  0.11890  \n","1    0.1860  0.2750  0.08902  \n","2    0.2430  0.3613  0.08758  \n","3    0.2575  0.6638  0.17300  \n","4    0.1625  0.2364  0.07678  \n","..      ...     ...      ...  \n","564  0.2216  0.2060  0.07115  \n","565  0.1628  0.2572  0.06637  \n","566  0.1418  0.2218  0.07820  \n","567  0.2650  0.4087  0.12400  \n","568  0.0000  0.2871  0.07039  \n","\n","[569 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-63140d9f-a4c2-4b28-8d06-12d1e03d9868\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>...</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>M</td>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>...</td>\n","      <td>25.380</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>M</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>...</td>\n","      <td>24.990</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>M</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>...</td>\n","      <td>23.570</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>...</td>\n","      <td>14.910</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>M</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>...</td>\n","      <td>22.540</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>M</td>\n","      <td>21.56</td>\n","      <td>22.39</td>\n","      <td>142.00</td>\n","      <td>1479.0</td>\n","      <td>0.11100</td>\n","      <td>0.11590</td>\n","      <td>0.24390</td>\n","      <td>0.13890</td>\n","      <td>0.1726</td>\n","      <td>...</td>\n","      <td>25.450</td>\n","      <td>26.40</td>\n","      <td>166.10</td>\n","      <td>2027.0</td>\n","      <td>0.14100</td>\n","      <td>0.21130</td>\n","      <td>0.4107</td>\n","      <td>0.2216</td>\n","      <td>0.2060</td>\n","      <td>0.07115</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>M</td>\n","      <td>20.13</td>\n","      <td>28.25</td>\n","      <td>131.20</td>\n","      <td>1261.0</td>\n","      <td>0.09780</td>\n","      <td>0.10340</td>\n","      <td>0.14400</td>\n","      <td>0.09791</td>\n","      <td>0.1752</td>\n","      <td>...</td>\n","      <td>23.690</td>\n","      <td>38.25</td>\n","      <td>155.00</td>\n","      <td>1731.0</td>\n","      <td>0.11660</td>\n","      <td>0.19220</td>\n","      <td>0.3215</td>\n","      <td>0.1628</td>\n","      <td>0.2572</td>\n","      <td>0.06637</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>M</td>\n","      <td>16.60</td>\n","      <td>28.08</td>\n","      <td>108.30</td>\n","      <td>858.1</td>\n","      <td>0.08455</td>\n","      <td>0.10230</td>\n","      <td>0.09251</td>\n","      <td>0.05302</td>\n","      <td>0.1590</td>\n","      <td>...</td>\n","      <td>18.980</td>\n","      <td>34.12</td>\n","      <td>126.70</td>\n","      <td>1124.0</td>\n","      <td>0.11390</td>\n","      <td>0.30940</td>\n","      <td>0.3403</td>\n","      <td>0.1418</td>\n","      <td>0.2218</td>\n","      <td>0.07820</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>M</td>\n","      <td>20.60</td>\n","      <td>29.33</td>\n","      <td>140.10</td>\n","      <td>1265.0</td>\n","      <td>0.11780</td>\n","      <td>0.27700</td>\n","      <td>0.35140</td>\n","      <td>0.15200</td>\n","      <td>0.2397</td>\n","      <td>...</td>\n","      <td>25.740</td>\n","      <td>39.42</td>\n","      <td>184.60</td>\n","      <td>1821.0</td>\n","      <td>0.16500</td>\n","      <td>0.86810</td>\n","      <td>0.9387</td>\n","      <td>0.2650</td>\n","      <td>0.4087</td>\n","      <td>0.12400</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>B</td>\n","      <td>7.76</td>\n","      <td>24.54</td>\n","      <td>47.92</td>\n","      <td>181.0</td>\n","      <td>0.05263</td>\n","      <td>0.04362</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.1587</td>\n","      <td>...</td>\n","      <td>9.456</td>\n","      <td>30.37</td>\n","      <td>59.16</td>\n","      <td>268.6</td>\n","      <td>0.08996</td>\n","      <td>0.06444</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.2871</td>\n","      <td>0.07039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 31 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63140d9f-a4c2-4b28-8d06-12d1e03d9868')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-63140d9f-a4c2-4b28-8d06-12d1e03d9868 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-63140d9f-a4c2-4b28-8d06-12d1e03d9868');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["df=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)\n","df = df.drop(columns=0)\n","df"]},{"cell_type":"markdown","source":["There are **30 features** and **1 binary label** (**M = malignant; B = benign**) per row. There are **569 data entries**."],"metadata":{"id":"rfUkeZ21rBNS"},"id":"rfUkeZ21rBNS"},{"cell_type":"markdown","source":["b) Use **sklearn.preprocessing.LabelEncoder** to turn the binary labels into numberical values."],"metadata":{"id":"avLi4mZurks1"},"id":"avLi4mZurks1"},{"cell_type":"code","execution_count":14,"id":"daf7d403","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"daf7d403","executionInfo":{"status":"ok","timestamp":1652132143045,"user_tz":-120,"elapsed":418,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}},"outputId":"2052e8ae-0d3a-4764-9b31-e28ddb3f9a20"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     1      2      3       4       5        6        7        8        9   \\\n","0     1  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n","1     1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017   \n","2     1  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790   \n","3     1  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n","4     1  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n","..   ..    ...    ...     ...     ...      ...      ...      ...      ...   \n","564   1  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890   \n","565   1  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791   \n","566   1  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302   \n","567   1  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200   \n","568   0   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000   \n","\n","         10  ...      22     23      24      25       26       27      28  \\\n","0    0.2419  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n","1    0.1812  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n","2    0.2069  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n","3    0.2597  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n","4    0.1809  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n","..      ...  ...     ...    ...     ...     ...      ...      ...     ...   \n","564  0.1726  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n","565  0.1752  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n","566  0.1590  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n","567  0.2397  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n","568  0.1587  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n","\n","         29      30       31  \n","0    0.2654  0.4601  0.11890  \n","1    0.1860  0.2750  0.08902  \n","2    0.2430  0.3613  0.08758  \n","3    0.2575  0.6638  0.17300  \n","4    0.1625  0.2364  0.07678  \n","..      ...     ...      ...  \n","564  0.2216  0.2060  0.07115  \n","565  0.1628  0.2572  0.06637  \n","566  0.1418  0.2218  0.07820  \n","567  0.2650  0.4087  0.12400  \n","568  0.0000  0.2871  0.07039  \n","\n","[569 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-6a56e7df-e272-4d68-83cc-1a8e771f3b9f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>...</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>...</td>\n","      <td>25.380</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>...</td>\n","      <td>24.990</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>...</td>\n","      <td>23.570</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>...</td>\n","      <td>14.910</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>...</td>\n","      <td>22.540</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>1</td>\n","      <td>21.56</td>\n","      <td>22.39</td>\n","      <td>142.00</td>\n","      <td>1479.0</td>\n","      <td>0.11100</td>\n","      <td>0.11590</td>\n","      <td>0.24390</td>\n","      <td>0.13890</td>\n","      <td>0.1726</td>\n","      <td>...</td>\n","      <td>25.450</td>\n","      <td>26.40</td>\n","      <td>166.10</td>\n","      <td>2027.0</td>\n","      <td>0.14100</td>\n","      <td>0.21130</td>\n","      <td>0.4107</td>\n","      <td>0.2216</td>\n","      <td>0.2060</td>\n","      <td>0.07115</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>1</td>\n","      <td>20.13</td>\n","      <td>28.25</td>\n","      <td>131.20</td>\n","      <td>1261.0</td>\n","      <td>0.09780</td>\n","      <td>0.10340</td>\n","      <td>0.14400</td>\n","      <td>0.09791</td>\n","      <td>0.1752</td>\n","      <td>...</td>\n","      <td>23.690</td>\n","      <td>38.25</td>\n","      <td>155.00</td>\n","      <td>1731.0</td>\n","      <td>0.11660</td>\n","      <td>0.19220</td>\n","      <td>0.3215</td>\n","      <td>0.1628</td>\n","      <td>0.2572</td>\n","      <td>0.06637</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>1</td>\n","      <td>16.60</td>\n","      <td>28.08</td>\n","      <td>108.30</td>\n","      <td>858.1</td>\n","      <td>0.08455</td>\n","      <td>0.10230</td>\n","      <td>0.09251</td>\n","      <td>0.05302</td>\n","      <td>0.1590</td>\n","      <td>...</td>\n","      <td>18.980</td>\n","      <td>34.12</td>\n","      <td>126.70</td>\n","      <td>1124.0</td>\n","      <td>0.11390</td>\n","      <td>0.30940</td>\n","      <td>0.3403</td>\n","      <td>0.1418</td>\n","      <td>0.2218</td>\n","      <td>0.07820</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>1</td>\n","      <td>20.60</td>\n","      <td>29.33</td>\n","      <td>140.10</td>\n","      <td>1265.0</td>\n","      <td>0.11780</td>\n","      <td>0.27700</td>\n","      <td>0.35140</td>\n","      <td>0.15200</td>\n","      <td>0.2397</td>\n","      <td>...</td>\n","      <td>25.740</td>\n","      <td>39.42</td>\n","      <td>184.60</td>\n","      <td>1821.0</td>\n","      <td>0.16500</td>\n","      <td>0.86810</td>\n","      <td>0.9387</td>\n","      <td>0.2650</td>\n","      <td>0.4087</td>\n","      <td>0.12400</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>0</td>\n","      <td>7.76</td>\n","      <td>24.54</td>\n","      <td>47.92</td>\n","      <td>181.0</td>\n","      <td>0.05263</td>\n","      <td>0.04362</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.1587</td>\n","      <td>...</td>\n","      <td>9.456</td>\n","      <td>30.37</td>\n","      <td>59.16</td>\n","      <td>268.6</td>\n","      <td>0.08996</td>\n","      <td>0.06444</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.2871</td>\n","      <td>0.07039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 31 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a56e7df-e272-4d68-83cc-1a8e771f3b9f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6a56e7df-e272-4d68-83cc-1a8e771f3b9f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6a56e7df-e272-4d68-83cc-1a8e771f3b9f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["#Use LabelEncoder to transform the Lable into numeric features\n","from sklearn.preprocessing import LabelEncoder\n","lb_enc = LabelEncoder()\n","df[1] = lb_enc.fit_transform(df[1])\n","df"]},{"cell_type":"markdown","source":["**M=1** and **B=0**"],"metadata":{"id":"j7Ac27dHvvs9"},"id":"j7Ac27dHvvs9"},{"cell_type":"markdown","source":["c) Use **sklearn.cross_validation.train_test_split** to split the data set into trainings (80%) and test (20%) data. Set **random_state=1**."],"metadata":{"id":"cFci489espCr"},"id":"cFci489espCr"},{"cell_type":"code","execution_count":15,"id":"d7d50994","metadata":{"id":"d7d50994","executionInfo":{"status":"ok","timestamp":1652132145401,"user_tz":-120,"elapsed":223,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}}},"outputs":[],"source":["#Split the data into 80% train and 20% test data \n","from sklearn.model_selection import train_test_split\n","data = df.drop(columns=1)\n","target= df[1]\n","x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=1)"]},{"cell_type":"markdown","source":["d) Use **sklearn.preprocessing.StandardScaler** for preprocessing (feature scaling) and PCA for dimensionality reduction with **sklearn.decomposition.PCA** and n_components=2. Use **sklearn.linear_model.LogisticRegression** as classifier with **random_state=1**. Put everything into a pipeline (**sklearn.pipeline.Pipeline)**."],"metadata":{"id":"WTuWnu8WtCoo"},"id":"WTuWnu8WtCoo"},{"cell_type":"code","execution_count":16,"id":"4c83aad6","metadata":{"id":"4c83aad6","executionInfo":{"status":"ok","timestamp":1652132148377,"user_tz":-120,"elapsed":435,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}}},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":17,"id":"0bab7b2d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0bab7b2d","executionInfo":{"status":"ok","timestamp":1652132149811,"user_tz":-120,"elapsed":310,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}},"outputId":"2d2e7f8e-642c-48cc-8308-65fa3c24c05c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA(n_components=2)),\n","                ('clf', LogisticRegression(random_state=1))])"]},"metadata":{},"execution_count":17}],"source":["#Setup a pipeline, which standardize the data for a PCA and applies a LogisticRegression on the data\n","pipe = Pipeline(steps=[\n","    ('scaler', StandardScaler()),('pca',PCA(n_components=2)),('clf',LogisticRegression(random_state=1))])\n","pipe.fit(x_train,y_train)"]},{"cell_type":"markdown","source":["e) Test with **pipeline.score** your model's accuracy. You should receive an accuracy of **0.947**."],"metadata":{"id":"B7XWvvsLty8E"},"id":"B7XWvvsLty8E"},{"cell_type":"code","execution_count":18,"id":"89a04399","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89a04399","executionInfo":{"status":"ok","timestamp":1652132153072,"user_tz":-120,"elapsed":304,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}},"outputId":"ddc66e18-6ca4-4718-d891-5a9041216012"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9473684210526315"]},"metadata":{},"execution_count":18}],"source":["pipe.score(x_test,y_test)"]},{"cell_type":"markdown","source":["Accuracy of **0.947** (94%). "],"metadata":{"id":"ZIaKqjm2uD9L"},"id":"ZIaKqjm2uD9L"},{"cell_type":"markdown","source":["f) Use **Recursive Feature Elimination** (**RFE**; **sklearn.feature_selection.RFECV**) for feature selection instead of PCA. Which and how many features are interesting for classification? Which (max.) accuracy on test data be reached with this step (instead of PCA)?"],"metadata":{"id":"-qBNStLPuPTg"},"id":"-qBNStLPuPTg"},{"cell_type":"code","execution_count":19,"id":"2b0bcdc0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b0bcdc0","executionInfo":{"status":"ok","timestamp":1652132158088,"user_tz":-120,"elapsed":1862,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}},"outputId":"70e61cf1-2e9f-4427-f259-32c894499ab1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True,  True,  True,  True, False,  True,  True,  True, False,\n","       False,  True, False,  True,  True, False,  True, False,  True,\n","       False,  True,  True,  True,  True,  True,  True, False,  True,\n","        True,  True,  True])"]},"metadata":{},"execution_count":19}],"source":["#Use the pipeline with a RFECV instead of a PCA and show wich features are selected.\n","from sklearn.feature_selection import RFECV\n","pipe2 = Pipeline(steps=[\n","    ('scaler', StandardScaler()),('rfecv',RFECV(estimator=LogisticRegression(random_state=1)))])\n","pipe2.fit(x_train,y_train)\n","pipe2['rfecv'].support_"]},{"cell_type":"code","execution_count":20,"id":"7c4d36cb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7c4d36cb","executionInfo":{"status":"ok","timestamp":1652132160234,"user_tz":-120,"elapsed":400,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}},"outputId":"ff366492-9538-4320-a0bd-0aacbb30d6b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of features: 22\n"]}],"source":["print('Number of features:',sum(pipe2['rfecv'].support_==True))"]},{"cell_type":"code","execution_count":21,"id":"d6b97cf4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6b97cf4","executionInfo":{"status":"ok","timestamp":1652132162401,"user_tz":-120,"elapsed":232,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}},"outputId":"d4ad07d6-94e9-4f3c-f286-995c2cb4d1f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Indices of the selected features: [2.0, 3.0, 4.0, 5.0, 7.0, 8.0, 9.0, 12.0, 14.0, 15.0, 17.0, 19.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 28.0, 29.0, 30.0, 31.0]\n"]}],"source":["imp_feature=x_test.columns.where(pipe2['rfecv'].support_==True).dropna().tolist()\n","print('Indices of the selected features:',imp_feature)"]},{"cell_type":"code","execution_count":22,"id":"95d89ac5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95d89ac5","executionInfo":{"status":"ok","timestamp":1652132163856,"user_tz":-120,"elapsed":188,"user":{"displayName":"Danilo Rosenthal","userId":"14867404785760024629"}},"outputId":"523a338b-fa93-4782-bd11-53409a876a75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9824561403508771"]},"metadata":{},"execution_count":22}],"source":["pipe2.score(x_test,y_test)"]},{"cell_type":"markdown","source":["REF selects **22** features and we can reach an accuracy of **0.982** (98%)."],"metadata":{"id":"TyFXHtuxvD15"},"id":"TyFXHtuxvD15"}],"metadata":{"kernelspec":{"display_name":"datascience","language":"python","name":"datascience"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"name":"Exercise_7.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}